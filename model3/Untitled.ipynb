{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f3fb4c2-6cc7-48f1-95da-16865ee4db13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae5c1c7f-32ca-4db4-a20f-c24764eb1fd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def clean_text(string: str, \n",
    "               punctuations = r'''!()-[]{};:'\"\\,<>./?@#$%^&*_~''',\n",
    "               stop_words = stopwords.words('english'),\n",
    "               # porter = PorterStemmer()\n",
    "               wnl = WordNetLemmatizer()\n",
    "              ):\n",
    "    \"\"\"\n",
    "    A method to clean text. It removes punctuations, stop words, applies lemmatization.\n",
    "    \"\"\"\n",
    "    # Removing the punctuations\n",
    "    for x in string.lower(): \n",
    "        if x in punctuations: \n",
    "            string = string.replace(x, \"\") \n",
    "\n",
    "    # Converting the text to lower\n",
    "    string = string.lower()\n",
    "\n",
    "    # Removing stop words\n",
    "    string = ' '.join([word for word in string.split() if word not in stop_words])\n",
    "\n",
    "    # stemming/lemmatizing words. That means changing word to its basic format, for example\n",
    "    # words 'fishing', 'fished', 'fischer' will be changed into a word 'fisch'\n",
    "    # lemmatization should be better because stemming changes words too much, for example\n",
    "    # business is changed into busi\n",
    "    # string = ' '.join([porter.stem(word) for word in string.split()])\n",
    "    string = ' '.join([wnl.lemmatize(word, pos = \"v\") for word in string.split()])\n",
    "\n",
    "    # Cleaning the whitespaces\n",
    "    string = re.sub(r'\\s+', ' ', string).strip()\n",
    "\n",
    "    return string\n",
    "\n",
    "def create_training_data(tokenizer,\n",
    "                         sentences_file,\n",
    "                         embed_matrix_file,\n",
    "                         model_folder,\n",
    "                         max_sen_len = None\n",
    "                        ):\n",
    "    \"\"\"\n",
    "    Creating a training and testing datasets self.x_train, self.x_test, self.y_train, self.y_test. This function\n",
    "    also creates and saves a tokenizer and a list of all unique tables names all_unique_values because when we load\n",
    "    a ready model those values are needed for the 'predict' function.\n",
    "    \"\"\"\n",
    "    sentences_tables = pd.read_excel(sentences_file).values\n",
    "    random.shuffle(sentences_tables)\n",
    "    clean_sentences = np.array([clean_text(sentence) for sentence in sentences_tables[:, 0]])\n",
    "\n",
    "    tokenizer.fit_on_texts(clean_sentences)\n",
    "\n",
    "    sequences = tokenizer.texts_to_sequences(clean_sentences)\n",
    "    if max_sen_len == None:\n",
    "        max_sen_len = np.max([len(seq) for seq in sequences])\n",
    "    x = pad_sequences(sequences, maxlen = max_sen_len)\n",
    "\n",
    "    embed_matrix = pd.read_csv(embed_matrix_file).values\n",
    "\n",
    "    x_train, x_test = train_test_split(x, test_size = 0.2)\n",
    "\n",
    "    with open(os.path.join(model_folder, 'tokenizer.json'), 'w') as file:\n",
    "        json.dump(tokenizer.to_json(), file)\n",
    "        \n",
    "    return x_train, x_test\n",
    "\n",
    "\n",
    "def get_coefs(word, *arr): \n",
    "    return word, list(np.asarray(arr, dtype='float'))\n",
    "\n",
    "\n",
    "def create_embedding_file(tokenizer,\n",
    "                          embed_file_src = r'model\\glove.840B.300d.txt', \n",
    "                          embed_file_trg = r'model\\model_embeddings.txt'\n",
    "                         ):\n",
    "    \"\"\"\n",
    "    This function will create an embedding file called embed_file_trg which will contain only those words \n",
    "    from embed_file_src which are present in the training dataset (tokenizer.word_index).\n",
    "    \"\"\"\n",
    "\n",
    "    embeddings = dict(get_coefs(*o.split(\" \")) for o in open(embed_file_src, errors = 'ignore'))\n",
    "    with open(embed_file_trg, 'w') as file:\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            word_vector = embeddings[word]\n",
    "            line = ' '.join(np.concatenate([[word], word_vector]))\n",
    "            file.write(line + '\\n')\n",
    "\n",
    "\n",
    "def create_embedding_matrix(tokenizer,\n",
    "                            model_folder,\n",
    "                            word_vec_dim,\n",
    "                            embed_file_path,\n",
    "                           ):\n",
    "    \"\"\"\n",
    "    A function to create an embedding matrix. This is a matrix where each row is a vector representing a word.\n",
    "    To create that matrix we use a word embedding file which path is equal to embedding_file_path.\n",
    "    embedding_matrix[row_number] is a vector representation for a word = list(tokenizer.word_index.keys())[row_number - 1]\n",
    "    First row of embedding_matrix are zeros. This matrix is needed to train a model.\n",
    "    \"\"\"\n",
    "    embeddings = dict(get_coefs(*o.split(\" \")) for o in open(embed_file_path, errors = 'ignore'))\n",
    "\n",
    "    # embedding_matrix[row_number] is a vector representation of a word = self.tokenizer.word_index.keys()[row_number - 1]\n",
    "    # first row in embedding_matrix is 0\n",
    "    embedding_matrix = np.zeros((len(tokenizer.word_counts) + 1, word_vec_dim))\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index > len(tokenizer.word_counts):\n",
    "            break\n",
    "        else:\n",
    "            try:\n",
    "                embedding_matrix[index] = embeddings[word]\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    pd.DataFrame(embedding_matrix).to_csv(os.path.join(model_folder, 'embedding_matrix.csv'))\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9a6c030-6b64-4d53-9cdf-18ae47d5b133",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "# max_sen_len = 20\n",
    "sentences_file = r'data\\sentences_tables.xlsx'\n",
    "embed_matrix_file = r'model\\embedding_matrix.csv'\n",
    "model_folder = 'model'\n",
    "word_vec_dim = 300\n",
    "embed_file_path = r'model\\model_embeddings.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa21b414-1a9d-4045-b551-9416b28cf16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = create_training_data(\n",
    "    tokenizer = tokenizer, \n",
    "    # max_sen_len = max_sen_len,\n",
    "    sentences_file = sentences_file,\n",
    "    embed_matrix_file = embed_matrix_file,\n",
    "    model_folder = model_folder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "703325ad-5693-45fb-8ca5-0632a439fcfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 11,  1, 16],\n",
       "       [ 0,  0,  2, ..., 26, 22, 11],\n",
       "       [ 0,  0,  0, ..., 15,  7, 12],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 15,  7, 12],\n",
       "       [ 0,  0,  0, ...,  7, 15, 12],\n",
       "       [ 0,  0,  0, ..., 13,  1, 10]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fbd939a-fe1a-4b2d-9b3b-b46858c3282e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_matrix = create_embedding_matrix(\n",
    "    tokenizer = tokenizer,\n",
    "    model_folder = model_folder,\n",
    "    word_vec_dim = word_vec_dim,\n",
    "    embed_file_path = embed_file_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a69efdd-4542-4dfc-8cb3-d65237cdf61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
       "         0.      ],\n",
       "       [-0.50318 ,  0.27905 , -0.045497, ...,  0.4781  ,  0.13005 ,\n",
       "        -0.014399],\n",
       "       [ 0.16082 ,  0.11008 , -0.28129 , ...,  0.12435 , -0.27433 ,\n",
       "         0.65513 ],\n",
       "       ...,\n",
       "       [-0.39054 , -0.55117 , -0.073466, ...,  0.34569 ,  0.30918 ,\n",
       "        -0.32873 ],\n",
       "       [ 0.049725, -0.48829 , -0.11179 , ...,  0.033829, -0.068756,\n",
       "        -0.43567 ],\n",
       "       [ 0.37492 , -0.052425, -0.60094 , ..., -0.36104 , -0.065253,\n",
       "        -0.1206  ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8854e78-9e2f-4fde-973c-209d545335c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('employee', 1)\n",
      "('user', 2)\n",
      "('cost', 3)\n",
      "('business', 4)\n",
      "('unit', 5)\n",
      "('office', 6)\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(tokenizer.word_index.items()):\n",
    "    print(item)\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "130632c9-bbf4-4a09-a7e1-e8c153935bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(Model):\n",
    "    def __init__(self,\n",
    "                 embedding_dim,\n",
    "                 lstm_out_size,\n",
    "                 batch_size,\n",
    "                 embed_matrix\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.lstm_out_size = lstm_out_size\n",
    "        self.batch_size = batch_size\n",
    "        self.embedding = layers.Embedding(\n",
    "            input_dim = embed_matrix.shape[0],\n",
    "            output_dim = embedding_dim,\n",
    "            embeddings_initializer = tf.keras.initializers.Constant(embed_matrix),\n",
    "            trainable = False\n",
    "        )\n",
    "        self.lstm = layers.LSTM(\n",
    "            units = self.lstm_out_size,\n",
    "            return_sequences = True,\n",
    "            return_state = True\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def call(self, x, state_h = None, state_c = None):\n",
    "        # x.shape = (batch_size, max_sen_len)\n",
    "        # x is a series of numbers which represent words\n",
    "        # state_h.shape = (batch_size, lstm_out_size)\n",
    "        \n",
    "        if state_h == None or state_c == None:\n",
    "            state_h, state_c = self.initialize_hidden_state()\n",
    "        \n",
    "        # make sure that the types are correct\n",
    "        x = tf.cast(x, tf.float32)\n",
    "        state_h = tf.cast(state_h, tf.float32)\n",
    "        state_c = tf.cast(state_c, tf.float32)\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        # x.shape after embedding = (batch_size, max_sen_len, embedding_dim)\n",
    "        # output.shape = (batch_size, max_sen_len, lstm_out_size)\n",
    "        # state_h.shape = (batch_size, lstm_out_size)\n",
    "        output, state_h, state_c = self.lstm(x, initial_state = [state_h, state_c])\n",
    "        return output, state_h, state_c\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        state_h = tf.zeros((self.batch_size, self.lstm_out_size))\n",
    "        state_c = tf.zeros((self.batch_size, self.lstm_out_size))\n",
    "        return state_h, state_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e07b1daa-cfc1-4cfe-85a6-a58ce5120f4f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 2, 10), dtype=float32, numpy=\n",
       " array([[[-0.01010686,  0.15246582,  0.27528095,  0.08459798,\n",
       "          -0.10636424, -0.00829592, -0.17434974,  0.06614996,\n",
       "           0.12349623, -0.02620884],\n",
       "         [ 0.09638108,  0.13594042,  0.04519174,  0.12317128,\n",
       "          -0.2049617 ,  0.04057549, -0.13176972,  0.00576828,\n",
       "           0.1808959 , -0.19541648]],\n",
       " \n",
       "        [[-0.01010686,  0.15246582,  0.27528095,  0.08459798,\n",
       "          -0.10636424, -0.00829592, -0.17434974,  0.06614996,\n",
       "           0.12349623, -0.02620884],\n",
       "         [ 0.09638108,  0.13594042,  0.04519174,  0.12317128,\n",
       "          -0.2049617 ,  0.04057549, -0.13176972,  0.00576828,\n",
       "           0.1808959 , -0.19541648]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 10), dtype=float32, numpy=\n",
       " array([[ 0.09638108,  0.13594042,  0.04519174,  0.12317128, -0.2049617 ,\n",
       "          0.04057549, -0.13176972,  0.00576828,  0.1808959 , -0.19541648],\n",
       "        [ 0.09638108,  0.13594042,  0.04519174,  0.12317128, -0.2049617 ,\n",
       "          0.04057549, -0.13176972,  0.00576828,  0.1808959 , -0.19541648]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 10), dtype=float32, numpy=\n",
       " array([[ 0.22702846,  0.3807187 ,  0.09366615,  0.21329811, -0.5073172 ,\n",
       "          0.10269465, -0.32337594,  0.01067035,  0.46416277, -0.3588056 ],\n",
       "        [ 0.22702846,  0.3807187 ,  0.09366615,  0.21329811, -0.5073172 ,\n",
       "          0.10269465, -0.32337594,  0.01067035,  0.46416277, -0.3588056 ]],\n",
       "       dtype=float32)>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Encoder(embedding_dim = 300,\n",
    "                 lstm_out_size = 10,\n",
    "                 batch_size = 2,\n",
    "                 embed_matrix = embed_matrix\n",
    "                 )\n",
    "\n",
    "x = np.array([[1, 2], [1, 2]])\n",
    "encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e586409-6d87-463c-90dd-40135c565e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 1 like in Jonathan Hui pdf\n",
    "class Bahdau_attention(layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.W1 = layers.Dense(units)\n",
    "        self.W2 = layers.Dense(units)\n",
    "        self.V = layers.Dense(1)\n",
    "        \n",
    "    def call(self, decoder_hidden, encoder_hidden):\n",
    "        # decoder_hidden.shape = (batch_size, hidden_size)\n",
    "        # decoder_hidden_time_axis.shape = (batch_size, 1, hidden_size)\n",
    "        decoder_hidden_time_axis = tf.expand_dims(decoder_hidden, 1)\n",
    "        \n",
    "        # encoder_hidden.shape = (batch_size, max_sen_len, hidden_size)\n",
    "        # argument for tanh shape = (batch_size, max_sen_len, hidden_size)\n",
    "        # score.shape = (batch_size, max_sen_len, 1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(decoder_hidden_time_axis) + self.W2(encoder_hidden)))\n",
    "        \n",
    "        # attention_weights.shape = (batch_size, max_sen_len, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis = 1)\n",
    "        \n",
    "        # context_vector.shape = (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * encoder_hidden\n",
    "        context_vector = tf.reduce_sum(context_vector, axis = 1)\n",
    "        \n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "398014c9-b9ab-4f29-84d1-7c96af06a3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 2, like in attention explanation pdf\n",
    "class Bahdau_attention(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense = layers.Dense(1)\n",
    "        \n",
    "    def call(self, decoder_state_h, encoder_states_h):\n",
    "        # decoder_state_h.shape = (batch_size, dec_state_size)\n",
    "        # encoder_states_h.shape = (batch_size, max_sen_len, enc_state_size)\n",
    "        \n",
    "        # make sure that the dtypes are correct\n",
    "        decoder_state_h = tf.cast(decoder_state_h, tf.float32)\n",
    "        encoder_states_h = tf.cast(encoder_states_h, tf.float32)\n",
    "        \n",
    "        # encoder_states_h_flattened.shape = (max_sen_len, enc_state_size)\n",
    "        encoder_states_h_flattened = tf.reshape(encoder_states_h, [-1, tf.shape(encoder_states_h)[2]])\n",
    "        batch_size, _, enc_state_size = tf.shape(encoder_states_h)\n",
    "        \n",
    "        # context_vector.shape = (batch_size, enc_state_size)\n",
    "        context_vector = np.zeros([batch_size, enc_state_size])\n",
    "        max_sen_len = encoder_states_h.shape[1]\n",
    "        for i in range(batch_size):\n",
    "            for j in range(max_sen_len):\n",
    "                e = []\n",
    "                for k in range(max_sen_len):\n",
    "                    x = tf.concat([decoder_state_h[i], encoder_states_h_flattened[i + k]], 0)\n",
    "                    # x.shape = (dec_state_size + enc_state_size)\n",
    "                    x = tf.expand_dims(x, 0)\n",
    "                    # x.shape = (1, dec_state_size + enc_state_size)\n",
    "                    e.append(tf.math.exp(self.dense(x)))\n",
    "                e = tf.stack(e)\n",
    "\n",
    "                attention_weight = e[j] / tf.math.reduce_sum(e)\n",
    "                context_vector[i] += attention_weight * encoder_states_h_flattened[i + j]\n",
    "        \n",
    "        return tf.cast(tf.stack(context_vector), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a9ec3a1b-a11a-496d-8cb8-95960056ab17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2.843929, 3.843929],\n",
       "       [2.843929, 3.843929]], dtype=float32)>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention = Bahdau_attention()\n",
    "decoder_state_h = tf.constant([[1,2,3], [4,5,6]])\n",
    "encoder_states_h = tf.constant([[[1,2], [4,5]], [[1,2], [4,5]]])\n",
    "\n",
    "attention(decoder_state_h, encoder_states_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15a6c0cc-731a-475c-bc69-bea3475e4fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, lstm_out_size, embed_matrix):\n",
    "        super().__init__()\n",
    "        self.lstm_out_size = lstm_out_size\n",
    "        self.embedding = layers.Embedding(\n",
    "            input_dim = embed_matrix.shape[0],\n",
    "            output_dim = embedding_dim,\n",
    "            embeddings_initializer = tf.keras.initializers.Constant(embed_matrix),\n",
    "            trainable = False\n",
    "        )\n",
    "        self.lstm = layers.LSTM(\n",
    "            units = self.lstm_out_size,\n",
    "            # return_sequences = True,\n",
    "            return_state = True\n",
    "        )\n",
    "        self.dense = layers.Dense(vocab_size)\n",
    "        self.attention = Bahdau_attention()\n",
    "        \n",
    "    def call(self, x, decoder_state_h, decoder_state_c, encoder_states_h):\n",
    "        # x.shape = (batch_size, 1)\n",
    "        # x is a single number for each batch representing a single word\n",
    "        # encoder_states_h.shape = (batch_size, max_sen_len, enc_state_size)\n",
    "        # decoder_state_h.shape = (batch_size, lstm_out_size)\n",
    "        \n",
    "        # make sure that the types are correct\n",
    "        x = tf.cast(x, tf.float32)\n",
    "        decoder_state_h = tf.cast(decoder_state_h, tf.float32)\n",
    "        decoder_state_c = tf.cast(decoder_state_c, tf.float32)\n",
    "        encoder_states_h = tf.cast(encoder_states_h, tf.float32)\n",
    "        \n",
    "        # context_vector.shape = (batch_size, enc_state_size)\n",
    "        context_vector = self.attention(decoder_state_h, encoder_states_h)\n",
    "        # shape of output of embedding layer = (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "        # x.shape after concatenation = (batch_size, 1, enc_state_size + embedding_dim)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis = 2)\n",
    "        \n",
    "        output, state_h, state_c = self.lstm(x, initial_state = [decoder_state_h, decoder_state_c])\n",
    "        \n",
    "        # output.shape = (batch_size, vocab_size)\n",
    "        output = self.dense(output)\n",
    "        \n",
    "        return output, state_h, state_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0bfb23f3-bb93-4967-9b92-8bdf3247ab4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "decoder = Decoder(vocab_size = 100, \n",
    "                  embedding_dim = 300, \n",
    "                  lstm_out_size = 20, \n",
    "                  embed_matrix = embed_matrix\n",
    "                 )\n",
    "\n",
    "x = tf.constant([[1], [2]])\n",
    "decoder_state_h = tf.constant([[i for i in range(20)], [i for i in range(20)]])\n",
    "decoder_state_c = tf.constant([[i for i in range(20)], [i for i in range(20)]])\n",
    "encoder_states_h = tf.constant([[[i for i in range(15)], [i for i in range(15)]], [[i for i in range(15)], [i for i in range(15)]]])\n",
    "\n",
    "output, state_h, state_c = decoder(x, decoder_state_h, decoder_state_c, encoder_states_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "53ffc42e-fa8e-4ca6-956a-948ae38af438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(inp, \n",
    "               targ, \n",
    "               # enc_state_h, \n",
    "               # enc_state_c, \n",
    "               batch_size, \n",
    "               encoder, \n",
    "               decoder, \n",
    "               loss_function, \n",
    "               optimizer):\n",
    "    # inp.shape = targ.shape (batch_size, max_sen_len)\n",
    "    # enc_state_h.shape = (batch_size, enc_state_size)\n",
    "    \n",
    "    # make sure that the types are correct\n",
    "    inp = tf.cast(inp, tf.float32)\n",
    "    targ = tf.cast(targ, tf.float32)\n",
    "    # enc_state_h = tf.cast(enc_state_h, tf.float32)\n",
    "    # enc_state_c = tf.cast(enc_state_c, tf.float32)\n",
    "    \n",
    "    batch_loss = 0\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        # enc_output.shape = (batch_size, max_sen_len, enc_state_size)\n",
    "        # enc_state_h.shape = (batch_size, state_size)\n",
    "        # enc_output, enc_state_h, enc_state_c = encoder(inp, enc_state_h, enc_state_c)\n",
    "        enc_output, enc_state_h, enc_state_c = encoder(inp)\n",
    "        dec_state_h = enc_state_h\n",
    "        dec_state_c = enc_state_c\n",
    "        \n",
    "        # dec_input.shape = (batch_size, 1)\n",
    "        dec_input = tf.expand_dims([0] * batch_size, 1)\n",
    "        \n",
    "        for t in range(targ.shape[1]):\n",
    "            prediction, dec_state_h, dec_state_c, = decoder(dec_input, dec_state_h, dec_state_c, enc_output)\n",
    "            # real value passed to loss_function needs to have shape (batch_size).\n",
    "            # It is a number representing a word from tokenizer.word_index. Real value = 0\n",
    "            # means that there was no word\n",
    "            batch_loss += loss_function(targ[:, t], prediction)\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "            \n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(batch_loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "16035f6f-2d3d-43bd-8f41-174494e45259",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(reduction = 'none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss = loss_object(real, pred)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype = loss.dtype)\n",
    "    loss *= mask\n",
    "    \n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a8ddff7-2151-45af-9547-df2a605e46cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([5.1293328e-02, 1.1920928e-07], dtype=float32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# real = tf.expand_dims(x_train[:2, 0], 1)\n",
    "# pred = tf.expand_dims(x_train[:2, 0], 1)\n",
    "\n",
    "real = tf.constant([1, 0])\n",
    "pred = tf.constant([[0.05, 0.95], [1, 0]])\n",
    "\n",
    "real = tf.cast(real, tf.float32)\n",
    "pred = tf.cast(pred, tf.float32)\n",
    "\n",
    "loss_object(real, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "423aca49-8c11-4305-bb06-80e0091323dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 20\n",
    "embedding_dim = 300\n",
    "\n",
    "inp = tf.constant(x_train)\n",
    "targ = tf.constant(x_train)\n",
    "\n",
    "decoder = Decoder(vocab_size = len(tokenizer.word_index.keys()) + 1,\n",
    "                  embedding_dim = embedding_dim,\n",
    "                  lstm_out_size = 100,\n",
    "                  embed_matrix = embed_matrix\n",
    "                 )\n",
    "\n",
    "encoder = Encoder(embedding_dim = embedding_dim,\n",
    "                 lstm_out_size = 100,\n",
    "                 batch_size = batch_size,\n",
    "                 embed_matrix = embed_matrix\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "48974688-4e2c-4b76-b5ea-b065ea4adc39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['decoder_3/bahdau_attention_3/dense_7/kernel:0', 'decoder_3/bahdau_attention_3/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['decoder_3/bahdau_attention_3/dense_7/kernel:0', 'decoder_3/bahdau_attention_3/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "Batch number: 0, Loss: 34.19960403442383\n",
      "Time per batch: 29.103997707366943\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['decoder_3/bahdau_attention_3/dense_7/kernel:0', 'decoder_3/bahdau_attention_3/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['decoder_3/bahdau_attention_3/dense_7/kernel:0', 'decoder_3/bahdau_attention_3/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "Batch number: 1, Loss: 35.694618225097656\n",
      "Time per batch: 29.27958047389984\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['decoder_3/bahdau_attention_3/dense_7/kernel:0', 'decoder_3/bahdau_attention_3/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['decoder_3/bahdau_attention_3/dense_7/kernel:0', 'decoder_3/bahdau_attention_3/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "Batch number: 2, Loss: 28.154685974121094\n",
      "Time per batch: 29.477375745773315\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['decoder_3/bahdau_attention_3/dense_7/kernel:0', 'decoder_3/bahdau_attention_3/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['decoder_3/bahdau_attention_3/dense_7/kernel:0', 'decoder_3/bahdau_attention_3/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "Batch number: 3, Loss: 30.59173011779785\n",
      "Time per batch: 31.320207178592682\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['decoder_3/bahdau_attention_3/dense_7/kernel:0', 'decoder_3/bahdau_attention_3/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['decoder_3/bahdau_attention_3/dense_7/kernel:0', 'decoder_3/bahdau_attention_3/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "Batch number: 4, Loss: 34.34357452392578\n",
      "Time per batch: 31.06994037628174\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['decoder_3/bahdau_attention_3/dense_7/kernel:0', 'decoder_3/bahdau_attention_3/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['decoder_3/bahdau_attention_3/dense_7/kernel:0', 'decoder_3/bahdau_attention_3/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "Batch number: 5, Loss: 34.71971893310547\n",
      "Time per batch: 30.91391058762868\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['decoder_3/bahdau_attention_3/dense_7/kernel:0', 'decoder_3/bahdau_attention_3/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['decoder_3/bahdau_attention_3/dense_7/kernel:0', 'decoder_3/bahdau_attention_3/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "Batch number: 6, Loss: 30.84465217590332\n",
      "Time per batch: 30.805311679840088\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['decoder_3/bahdau_attention_3/dense_7/kernel:0', 'decoder_3/bahdau_attention_3/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['decoder_3/bahdau_attention_3/dense_7/kernel:0', 'decoder_3/bahdau_attention_3/dense_7/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "Batch number: 7, Loss: 30.275360107421875\n",
      "Time per batch: 30.687577307224274\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [57], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m inp_batch \u001b[38;5;241m=\u001b[39m inp[batch_number \u001b[38;5;241m*\u001b[39m batch_size : (batch_number \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m batch_size, :]\n\u001b[0;32m      6\u001b[0m targ_batch \u001b[38;5;241m=\u001b[39m targ[batch_number \u001b[38;5;241m*\u001b[39m batch_size : (batch_number \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m batch_size, :]\n\u001b[1;32m----> 8\u001b[0m batch_loss \u001b[38;5;241m=\u001b[39m train_step(inp \u001b[38;5;241m=\u001b[39m inp_batch, \n\u001b[0;32m      9\u001b[0m                        targ \u001b[38;5;241m=\u001b[39m targ_batch,\n\u001b[0;32m     10\u001b[0m                        batch_size \u001b[38;5;241m=\u001b[39m batch_size,\n\u001b[0;32m     11\u001b[0m                        encoder \u001b[38;5;241m=\u001b[39m encoder, \n\u001b[0;32m     12\u001b[0m                        decoder \u001b[38;5;241m=\u001b[39m decoder, \n\u001b[0;32m     13\u001b[0m                        loss_function \u001b[38;5;241m=\u001b[39m loss_function, \n\u001b[0;32m     14\u001b[0m                        optimizer \u001b[38;5;241m=\u001b[39m optimizer\n\u001b[0;32m     15\u001b[0m                       )\n\u001b[0;32m     16\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_loss\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBatch number: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn [56], line 33\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(inp, targ, batch_size, encoder, decoder, loss_function, optimizer)\u001b[0m\n\u001b[0;32m     30\u001b[0m dec_input \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims([\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m batch_size, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(targ\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]):\n\u001b[1;32m---> 33\u001b[0m     prediction, dec_state_h, dec_state_c, \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdec_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdec_state_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdec_state_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# real value passed to loss_function needs to have shape (batch_size).\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;66;03m# It is a number representing a word from tokenizer.word_index. Real value = 0\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;66;03m# means that there was no word\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     batch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_function(targ[:, t], prediction)\n",
      "File \u001b[1;32m~\\Documents\\projects\\my_projects\\python_venv\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\Documents\\projects\\my_projects\\python_venv\\venv\\lib\\site-packages\\keras\\engine\\training.py:561\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    557\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(inputs, \u001b[38;5;241m*\u001b[39mcopied_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    559\u001b[0m     layout_map_lib\u001b[38;5;241m.\u001b[39m_map_subclass_model_variable(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layout_map)\n\u001b[1;32m--> 561\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Documents\\projects\\my_projects\\python_venv\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\Documents\\projects\\my_projects\\python_venv\\venv\\lib\\site-packages\\keras\\engine\\base_layer.py:1132\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1131\u001b[0m ):\n\u001b[1;32m-> 1132\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m call_fn(inputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1135\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32m~\\Documents\\projects\\my_projects\\python_venv\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "Cell \u001b[1;32mIn [10], line 32\u001b[0m, in \u001b[0;36mDecoder.call\u001b[1;34m(self, x, decoder_state_h, decoder_state_c, encoder_states_h)\u001b[0m\n\u001b[0;32m     29\u001b[0m encoder_states_h \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(encoder_states_h, tf\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# context_vector.shape = (batch_size, enc_state_size)\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m context_vector \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder_state_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_states_h\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# shape of output of embedding layer = (batch_size, 1, embedding_dim)\u001b[39;00m\n\u001b[0;32m     34\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x)\n",
      "File \u001b[1;32m~\\Documents\\projects\\my_projects\\python_venv\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\Documents\\projects\\my_projects\\python_venv\\venv\\lib\\site-packages\\keras\\engine\\base_layer.py:1132\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1131\u001b[0m ):\n\u001b[1;32m-> 1132\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m call_fn(inputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1135\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32m~\\Documents\\projects\\my_projects\\python_venv\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "Cell \u001b[1;32mIn [9], line 30\u001b[0m, in \u001b[0;36mBahdau_attention.call\u001b[1;34m(self, decoder_state_h, encoder_states_h)\u001b[0m\n\u001b[0;32m     28\u001b[0m     x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(x, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m# x.shape = (1, dec_state_size + enc_state_size)\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m     e\u001b[38;5;241m.\u001b[39mappend(tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m     31\u001b[0m e \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mstack(e)\n\u001b[0;32m     33\u001b[0m attention_weight \u001b[38;5;241m=\u001b[39m e[j] \u001b[38;5;241m/\u001b[39m tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mreduce_sum(e)\n",
      "File \u001b[1;32m~\\Documents\\projects\\my_projects\\python_venv\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\Documents\\projects\\my_projects\\python_venv\\venv\\lib\\site-packages\\keras\\engine\\base_layer.py:1132\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1131\u001b[0m ):\n\u001b[1;32m-> 1132\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m call_fn(inputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1135\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32m~\\Documents\\projects\\my_projects\\python_venv\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\projects\\my_projects\\python_venv\\venv\\lib\\site-packages\\keras\\layers\\core\\dense.py:252\u001b[0m, in \u001b[0;36mDense.call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    249\u001b[0m         outputs\u001b[38;5;241m.\u001b[39mset_shape(output_shape)\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_bias:\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_add\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    255\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(outputs)\n",
      "File \u001b[1;32m~\\Documents\\projects\\my_projects\\python_venv\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\Documents\\projects\\my_projects\\python_venv\\venv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32m~\\Documents\\projects\\my_projects\\python_venv\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:3554\u001b[0m, in \u001b[0;36mbias_add\u001b[1;34m(value, bias, data_format, name)\u001b[0m\n\u001b[0;32m   3551\u001b[0m   value \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(value, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3552\u001b[0m   bias \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(bias, dtype\u001b[38;5;241m=\u001b[39mvalue\u001b[38;5;241m.\u001b[39mdtype, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 3554\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_nn_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_add\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\projects\\my_projects\\python_venv\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py:901\u001b[0m, in \u001b[0;36mbias_add\u001b[1;34m(value, bias, data_format, name)\u001b[0m\n\u001b[0;32m    899\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m    900\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBiasAdd\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m    904\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "stime = time.time()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch_number in range(len(inp) // batch_size):\n",
    "        inp_batch = inp[batch_number * batch_size : (batch_number + 1) * batch_size, :]\n",
    "        targ_batch = targ[batch_number * batch_size : (batch_number + 1) * batch_size, :]\n",
    "        \n",
    "        batch_loss = train_step(inp = inp_batch, \n",
    "                               targ = targ_batch,\n",
    "                               batch_size = batch_size,\n",
    "                               encoder = encoder, \n",
    "                               decoder = decoder, \n",
    "                               loss_function = loss_function, \n",
    "                               optimizer = optimizer\n",
    "                              )\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        print(f'Batch number: {batch_number}, Loss: {batch_loss / batch_size}')\n",
    "        print(f'Time per batch: {(time.time() - stime) / (batch_number + 1)}')\n",
    "        \n",
    "    print(f'\\nEpoch: {epoch}, Loss: {total_loss / ((batch_number + 1) * batch_size)}')\n",
    "    print(f'Time per epoch: {(time.time() - stime) / (epoch + 1)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01287fe-3046-471e-8839-c24375ec2207",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
